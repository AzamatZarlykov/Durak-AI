\chapter{Artificial Intelligence Agents}
\label{AIAgents}

Durak features five distinct artificial intelligence (AI) agents: Random, Greedy, Smart, Minimax, and MCTS. In this chapter, we will delve into the characteristics and behaviors of each of these agents in order to gain a better understanding of their nature. 

\section{Random Agent}
The random decision algorithm is a basic approach that simply selects a choice of actions at random, as its name suggests, when presented with a decision. It serves as a foundational reference point for comparison with more advanced algorithms, as well as serving as a demonstration of the concept's feasibility. 

\begin{figure}[h]
\captionsetup{justification=centering}
\begin{lstlisting}[frame=single]
public override Card? Move(GameView gameView)
{
    List<Card?> cards = gameView.Actions(excludePassTake: true);

    // cannot attack/defend
    if (cards.Count == 1 && cards[0] is null)
    {
        return null;
    }

    // include the case when the ai can decide to pass/take
    // even if it can defend/attack (20% chance)
    // allow only when the first attack was given
    int rn = random.Next(0, 100);
    if (rn <= 20 && gameView.bout.GetAttackingCards().Count > 0)
    {
        return null;
    }

    return cards[random.Next(cards.Count)];
}
\end{lstlisting}
\caption{A representation of Move method of the Random agent}
\label{fig:randomMove}
\end{figure}

In Figure \ref{fig:randomMove}, the Move method for the Random agent is presented. When there are no available moves to be made (i.e., the \texttt{gameView.Actions(...)} method returns an null at the first index of the list), the agent interprets this as a Pass if it is the attacker, or as a Take if it is the defender. Given that there are multiple options available, the random agent has a 20\% probability of randomly deciding to either Pass or Take the card, depending on its role. The choice of a 20\% probability is arbitrary, but it represents a reasonable balance between actively selecting a card and opting to pass or take.


\section{Rule-Based Heuristic Agents}

Rule-based heuristic agents are artificial intelligence (AI) agents that use a set of predefined rules, heuristics or strategies to make decisions. These rules are designed to capture the key characteristics of a problem or task, and they are used by the agent to determine the best course of action to take in a given situation.

The strategies employed by the agents in this section were developed through the accumulation of experience gained over multiple games. These strategies are not guaranteed to produce victory in every game, but they increase the chances of winning by making safe moves based on predefined rules. 

\subsection{Greedy Agent}

It has been observed through years of playing this game that the optimal move in any given game state is to play the card with the lowest value. As such, the greedy agent employs a predetermined strategy in which it selects the lowest ranked card for attack or defense based on the current turn. Specifically, if the agent is attacking, it will choose the lowest valued card to attack with. If the agent is defending, it will select the lowest valued card to defend against an incoming attack. To provide an example, consider the scenario described in section \ref{illustration}, in which Player A attacks with 6$\textcolor{red}{\heartsuit}$ as a first turn. Among all the possible options, which includes 8$\textcolor{red}{\heartsuit}$, A$\textcolor{red}{\heartsuit}$, 6$\textcolor{black}{\spadesuit}$, to select to defend the attacking card, Player B chooses 8$\textcolor{red}{\heartsuit}$ which is the lowest rank value in their hand to defend against the attacking card. This decision-making process aligns with the strategy employed by a greedy agent, which aims to maximize their own short-term gain at the expense of potentially more optimal long-term outcomes.

\begin{figure}[h]
\captionsetup{justification=centering}
\begin{lstlisting}[frame=single]
function Move(gameView)
  moves = Actions(gameView)
  if HasNull(moves) then:
  	return NULL
  else
  	return GetCard(moves)

function GetCard(possbileCards, gw)
  noTrumpCards <- FilteroutNontrumpCards(possibleCards)
  if size(noTrumpCards) == 0 then
	if EarlyGame(gw) then
	  if Turn(gw) == ATTACK && size(GetBoutAttackCards(gw)) > 0 then
		return NULL
	  else
		return LowestRank(possibleCards)
	else
		return LowestRank(possibleCards)
  else
	return LowestRank(noTrumpCards)
\end{lstlisting}
\caption{A pseudocode of Move method of the Greedy agent}
\label{fig:greedyMove}
\end{figure}

The pseudocode shown in Figure \ref{fig:greedyMove} outlines the steps taken by the greedy agent to evaluate its options and make a decision. Specifically inside the \texttt{Move} method, the agent utilizes the \texttt{Actions} method to obtain a list of all possible actions it can take based on the current game state. If no actions are available, the agent will either pass or take a card, depending on its role in the game. However, if there are available actions, the agent will use the \texttt{GetCard} method to identify the card with the lowest value among the possible moves and select it as its next action. To ensure that the greedy agent is able to maximize its gain, we filter out any non-trump cards from the list of available options when determining the agent's next move. If the agent has a choice between non-trump cards, it will naturally select the one with the lowest rank value. However, if the agent only has trump cards to choose from, we must consider the \textbf{stage} of the game in order to make an optimal decision. In this context, the \textbf{early game} refers to any point in the game when there are still cards remaining in the deck, while the \textbf{end game} occurs when the deck is depleted. If the greedy agent is acting as an attacker and has the option to pass the attack, it is generally better to do so during the early game, as this allows the agent to preserve its trump cards for use in the end game, when they are likely to be more valuable. On the other hand, if the greedy agent is defending, it does not matter whether it uses trump cards or not at any stage of the game, as giving up these cards is preferable to taking the entire bout.

\subsection{Smart Agent}
\label{smart}
A smart agent using rule-based heuristics can exhibit improved performance compared to a greedy agent. This is because the smart agent utilizes rules that take into account the opponent's hand, providing a strategic advantage. One specific rule that may be implemented during the defensive stage is the selection of a defending card with a rank that the opponent does not possess. If it is not possible to utilize the aforementioned defensive strategy due to the opponent holding cards of the same rank as the available defending cards, the agent may choose to defend with the card of the lowest rank.  The implementation of the method is represented in the figure \ref{fig:defStratSmart}. This rule aims to prevent further attacks in the same bout by mitigating the opponent's options. While this rule may not be the most effective in every scenario, it has demonstrated successful outcomes in certain situations.

\begin{figure}[h]
\captionsetup{justification=centering}
\begin{lstlisting}[frame=single]
private Card? DefendingStrategy(List<Card> oHand, List<Card> cards)
{
     foreach (Card card in cards)
     {
          if (!oHand.Any(c => c.rank == card.rank))
          {
               return card;
           }
     }

     return Helper.GetLowestRank(cards);
}
\end{lstlisting}
\caption{A pseudocode of Move method of the Greedy agent, where oHand list is the opponent's hand and cards list is the possible cards for the defense.}
\label{fig:defStratSmart}
\end{figure}

Moreover, a smart agent may employ a strategy that leverages the concept of \textbf{weaknesses} in order to gain an advantage. A weakness for a player, referred to as player P, is defined as a rank r that meets the following criteria: 
\begin{enumerate}
	\item player P's hand contains at least one card of rank r, and
	\item for each suit s of rank r in player P's hand, there exists a rank r$'$ \> r such that the opponent holds a card of rank r$'$ and suit s \citep{Bonnet2016TheCO}.
\end{enumerate}

To clarify the concept of weaknesses, consider the following scenario: Player P holds the cards 10$\textcolor{red}{\heartsuit}$, 10$\textcolor{black}{\spadesuit}$, and K$\textcolor{red}{\diamondsuit}$, while player O holds Q$\textcolor{red}{\heartsuit}$, Q$\textcolor{black}{\spadesuit}$, and J$\textcolor{black}{\clubsuit}$. In this case, player P has a weakness at rank 10, as it satisfies the two conditions outlined in the definition of weakness. Specifically, player P holds at least one card of rank 10 (10$\textcolor{red}{\heartsuit}$ and 10$\textcolor{black}{\spadesuit}$), and for each suit of rank 10 in player P's hand (10$\textcolor{red}{\heartsuit}$ and 10$\textcolor{black}{\spadesuit}$), the opponent holds a card of higher rank (Q$\textcolor{red}{\heartsuit}$ and Q$\textcolor{black}{\spadesuit}$, respectively).

One limitation of this strategy is that it is only applicable in open-world environments, where the player is able to gather information about their opponent's hand in order to identify weakness in their hand. 

Now that the concept of weakness has been adequately defined, we can proceed to examine a new strategy that utilizes this concept. \textit{If player P only possesses a single weakness at rank r during their turn, then they have a winning strategy} \citep{Bonnet2016TheCO}. In the given example, player P possesses a weakness of rank 10. According to the aforementioned statement, this implies that player P has a winning strategy and can outmaneuver their opponent. This is indeed the case. To initiate the attack, player P can utilize all non-weakness rank cards, such as the K$\textcolor{red}{\diamondsuit}$. The opponent must take the attacking card, as they are unable to defend against it due to K being a non-weakness rank. In the subsequent bout, it remains player P's turn and they can attack all remaining weakness cards to become a winner.

As previously mentioned, the weakness strategy is only effective in open world games where players are able to view each other's cards. However, this method is not applicable in real-life situations and presents difficulties in its use. Nonetheless, the weakness strategy can still be utilized in closed-world games, but only in the endgame when the deck is exhausted. This is because when players have used up the entire deck, it implies that certain cards played during the bout have been placed in the discard pile. This allows the players to deduce the opponent's cards through deduction and successfully use the strategy for their advantage. A smart agent adheres to this principle, which, while not being a common occurrence in the game, is highly effective and ensures victory for the smart agent.

\section{Minimax Agent}
\label{minimax}

In this chapter, we will discuss the application of the minimax algorithm to the card game Durak. Specifically, the importance of the parameters in the minimax algorithm in the Durak Command Line Interface (CLI) as well as what heuristic functions that are included to evaluate the game state. Through this discussion, we will gain a deeper understanding of the functions and responsibilities of each parameter in the minimax algorithm as it pertains to the Durak game.

The minimax algorithm is a decision-making algorithm often used in two-player turn-based perfect information games, such as chess, tic-tac-toe, and Go \citep{AI4Ed}. It is called minimax because it tries to minimize the maximum loss that a player can incur. It operates by constructing a game tree, with each node representing a potential game state, and the branches representing the possible moves that can be made from that state. The minimax algorithm then traverses the tree, evaluating the value of each node using a combination of recursive calculations and a heuristic evaluation function. When applied to the entire tree, the minimax values produced by this algorithm accurately reflect the outcome of the game with perfect play by both players.

However, due to the exponential increase in the size of the tree as the search depth increases, it is often infeasible to search the entire tree. As a result, the minimax algorithm must be terminated at some depth, and the minimax value for a given node is approximated using a heuristic evaluation function. This function assigns a score to the current game state based on a set of predefined criteria, which will be discussed further in this section. While the use of a heuristic evaluation function introduces some error into the minimax values, it allows the algorithm to produce reasonable results in a reasonable amount of time.

\subsection{Basic Heuristic}
The basic heuristic function utilizes predetermined criteria to evaluate the game state, using the contents of the players' hands, the size of the players' hands, and the presence of any weaknesses. It should be noted that this is not the only method of evaluating the state, and there are potentially numerous other criteria that could be incorporated into the heuristic function. However, the criteria mentioned are considered to be the primary ones used in the basic heuristic function. It is important to note that this approach to evaluating the game state is based on a heuristic function, which is an estimation rather than a definitive measure of the value of a state.

\begin{figure}[h]
\captionsetup{justification=centering}
\begin{lstlisting}[frame=single]
private int ConvertHandToValue(List<Card> hand, GameView gw)
{
    const int TOTALCARDS = 9;
    int value = 0;

    foreach (Card card in hand)
    {
        if (gw.includeTrumps && card.suit == gw.trumpCard!.suit)
            value += (int)card.rank + TOTALCARDS;
        else
            value += (int)card.rank;
    }
    return value;
}

private int EvaluatePlayerHandToValue(GameView gw) =>
    ConvertHandToValue(gw.players[0].GetHand(), gw) -
    ConvertHandToValue(gw.players[1].GetHand(), gw);
\end{lstlisting}
\caption{A representation of basic heuristic function evaluating the state based on the players' hand value}
\label{fig:BHPlayersHandValue}
\end{figure}

In order to evaluate the state of a card game based on the cards held by each player, the heuristic function begins by computing the individual hand value of each player. Prior to beginning this calculation, the value of each card must be determined. This can be done by assigning the value of a card as its rank. For example, if player P holds the cards 6$\textcolor{red}{\heartsuit}$ and A$\textcolor{red}{\heartsuit}$, the value of their hand would be 20 (6 + 14). It is common for trump cards to be considered powerful and, as such, they may be assigned a higher value. To achieve this, the value of a trump card can be calculated by adding its rank to the total number of ranks in the deck. For example, the value of a trump card with rank 6 would be calculated as 6 + the total number of ranks in the deck (6, 7, ..., K, A). After the individual hand value of each player has been calculated, a basic heuristic function may be used to evaluate the game state. This can be done by subtracting the hand value of player P from that of player O. The result of this calculation can then be used to represent the game state. How this is achieved can be view in the figure \ref{fig:BHPlayersHandValue}. It should be noted that this method of evaluating the game state is only suitable for use when the players have an equal number of cards. When the players have an equal number of cards, these factors can be accurately compared and used to evaluate the state. In past experiments, using this evaluation method with players who have an equal number of cards has been found to produce more accurate and reliable results.

\begin{figure}[h]
\captionsetup{justification=centering}
\begin{lstlisting}[frame=single]
private int EvaluateHandSize(GameView gw)
{
     int pHandSize = gw.players[0].GetNumberOfCards();
     int oHandSize = gw.players[1].GetNumberOfCards();

     // hand size matters in the late game
     pHandSize = (gw.isEarlyGame ? pHandSize : pHandSize * 15);
     oHandSize = (gw.isEarlyGame ? oHandSize : oHandSize * 15);

     return (pHandSize - oHandSize) * -1;
}
\end{lstlisting}
\caption{A representation of basic heuristic function evaluating the state based on the players' hand size value}
\label{fig:BHPlayerHandSize}
\end{figure}

Another criterion that may be used to evaluate the state of a card game is the size of the players' hands. The number of cards held by each player can provide insight into the likely outcome of the game. This can be done by subtracting the size of player P's hand from that of player O's hand. In the end game, the value of the hand size is given additional weight by being multiplied by a factor, such as 15, which is arbitrarily selected. This is because the number of cards held at the end of the game can be particularly important in determining the outcome. It is important to note that the resulting value is inverted, by being multiplied by -1, because a player with more cards is generally considered to be at a disadvantage. The method being described is illustrated in a figure, labeled as Figure \ref{fig:BHPlayerHandSize}.

\begin{figure}[h]
\captionsetup{justification=centering}
\begin{lstlisting}[frame=single]
private int EvaluateState(GameView gw)
{
    int score = 0;
    //1) get the value of the hand only if the hand sizes are the same
    if (gw.players[0].GetNumberOfCards() == gw.players[1].GetNumberOfCards())
    {
        score += EvaluatePlayerHandToValue(gw);
    }
    // 2) size of the hand: smaller -> better 
    score += EvaluateHandSize(gw);
    // 3) weaknesses 
    if (!gw.isEarlyGame)
    {
       score += EvaluateWeaknesses(gw);
    }
    return score;
}
\end{lstlisting}
\caption{A representation of basic heuristic function}
\label{fig:basicEval}
\end{figure}

As a final criterion for evaluating the game state, it is possible to consider the existence of weakness in the state. This concept was discussed in more detail in section \ref{smart}. The occurrence of this type of scenario is relatively rare, as it only occurs in specific game environments. However, if a player does happen to have only one weakness in a particular game state, it can provide a strong advantage and increase the likelihood of winning the game. As a result, a basic heuristic function may assign a high value to this type of game state.

Figure \ref{fig:basicEval} illustrates the basic evaluation function, which combines the values obtained from the various criteria discussed earlier to assign a single value to the game state. The function adds together the values calculated for each criterion, resulting in a single value that represents the estimated value of the state. This value is then returned to the minimax function, which can use it to evaluate the state and guide decision-making.

\subsection{Playout Heuristic}



\section{Monte-Carlo Tree Search Agent}
\label{MCTS}

\section{Closed World Sampling}